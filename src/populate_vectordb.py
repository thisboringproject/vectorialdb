import psycopg2
import numpy as np
from pgvector.psycopg2 import register_vector
import random

# --- CONFIGURACI√ìN ---
DB_CONFIG = {
    "host": "localhost",
    "port": "5432",
    "database": "vector_database",
    "user": "admin",
    "password": "admin123"
}

# Definimos 3 dimensiones para coincidir con el ejemplo anterior.
# En un caso real con OpenAI usar√≠as 1536, o con HuggingFace 384/768.
VECTOR_DIM = 3 

def get_db_connection():
    conn = psycopg2.connect(**DB_CONFIG)
    # Esto es CR√çTICO: Permite a psycopg2 entender el tipo de dato 'vector'
    register_vector(conn)
    return conn

def setup_database(cursor):
    print("üõ†Ô∏è  Configurando base de datos...")
    # Asegurar que la extensi√≥n existe
    cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
    
    # Reiniciar la tabla para pruebas limpias
    cursor.execute("DROP TABLE IF EXISTS documents;")
    
    # Crear tabla con la dimensi√≥n espec√≠fica
    create_table_query = f"""
    CREATE TABLE documents (
        id bigserial PRIMARY KEY,
        title text,
        content text,
        embedding vector({VECTOR_DIM})
    );
    """
    cursor.execute(create_table_query)
    print("‚úÖ Tabla 'documents' creada.")

def generate_fake_data(num_records=10):
    print(f"üé≤ Generando {num_records} registros de prueba...")
    data = []
    topics = ["Inteligencia Artificial", "Bases de Datos", "Docker", "Python", "Cloud"]
    
    for i in range(num_records):
        title = f"{random.choice(topics)} - Art√≠culo {i+1}"
        content = f"Este es un contenido de prueba generado autom√°ticamente para el ID {i+1}."
        
        # Generar un vector aleatorio normalizado (simulando un embedding real)
        # Usamos numpy para crear floats aleatorios
        vector = np.random.rand(VECTOR_DIM).astype(np.float32)
        
        data.append((title, content, vector))
    
    return data

def insert_data(conn, data):
    cur = conn.cursor()
    print("üöÄ Insertando datos en Postgres...")
    
    # Inserci√≥n eficiente
    query = "INSERT INTO documents (title, content, embedding) VALUES (%s, %s, %s)"
    
    try:
        cur.executemany(query, data)
        conn.commit()
        print(f"‚úÖ Se insertaron {len(data)} registros exitosamente.")
    except Exception as e:
        print(f"‚ùå Error al insertar: {e}")
        conn.rollback()
    finally:
        cur.close()

def search_similarity(conn):
    cur = conn.cursor()
    print("\nüîç Probando b√∫squeda sem√°ntica...")
    
    # Vector de consulta (simulado)
    query_vector = np.random.rand(VECTOR_DIM).astype(np.float32)
    print(f"   Vector Query: {query_vector}")
    
    # B√∫squeda usando el operador <-> (Distancia Euclidiana/L2)
    # O podr√≠as usar <=> para Similitud Coseno
    search_sql = """
    SELECT title, content, embedding <-> %s AS distance
    FROM documents
    ORDER BY distance ASC
    LIMIT 3;
    """
    
    cur.execute(search_sql, (query_vector,))
    results = cur.fetchall()
    
    print("\nüèÜ Top 3 Resultados m√°s cercanos:")
    for row in results:
        print(f"   - [Distancia: {row[2]:.4f}] {row[0]}")
    
    cur.close()

if __name__ == "__main__":
    try:
        connection = get_db_connection()
        cursor = connection.cursor()
        
        setup_database(cursor)
        
        fake_data = generate_fake_data(20) # Generamos 20 documentos
        insert_data(connection, fake_data)
        
        search_similarity(connection)
        
        cursor.close()
        connection.close()
        print("\n‚ú® Script finalizado correctamente.")
        
    except Exception as e:
        print(f"\n‚ùå Error cr√≠tico de conexi√≥n: {e}")
        print("Aseg√∫rate de que el contenedor Docker est√© corriendo con: docker-compose up -d")